[[CH-Memory]]
== 内存子系统: 栈、堆以及垃圾收集

在深入研究 ERTS 的内存子系统之前，我们需要有一些基本的词汇表，并了解现代操作系统中程序内存布局的一般情形。在这个回顾部分中，我将假设程序被编译成一个 ELF 可执行文件，并运行在类似 IA-32 / AMD64 架构的 Linux 上。布局和术语对于编译ERTS的所有操作系统基本上是相同的。

一个程序的内存布局看起来像这样：

[[program_memory_layout]]
.Program Memory Layout

[ditaa]
----
 high
 addresses
        +--------------+
        |   Arguments  |
        |     ENV      |
        +--------------+
        |    Stack     | --+
        |      |       |   | Can grow
        |      v       |   | dynamically
        |              | --+
        +--------------+
        |              | -------------------------------+
        +--------------+                                |
        |    memory    |                                |
        |      map     | -- files or anonymous          |
        |    segment   |                                |
        +--------------+                                |
        |              |                                | Memory
        +--------------+                                | Mapping
        | Thread Stack | --+                            | Region
        |      |       |   | Statically allocated       |
        |      v       |   | on thread start.           |
        |              | --+                            |
        +--------------+                                |
        |              |                                |
        +--------------+                                |
        | Thread Stack | --+                            |
        |      |       |   | Statically allocated       |
        |      v       |   | on thread start.           |
        |              | --+                            |
        +--------------+                                |
        |              | -------------------------------+
        +--------------+ brk
        |              | --+
        |      ^       |   | Can grow
        |      |       |   | dynamically
        |     Heap     | --+
        +--------------+ start_brk
        |     BSS      | --  Static variables initialized to zero
        +--------------+
        |     Data     | --+
        +--------------+   | Binary (disk image)
        |     Code     | --+
        +--------------+
 low
 addresses


----

尽管这幅图看起来令人生畏，但它仍然是一种简化。(要想全面理解内存子系统，请阅读《深入理解Linux内核》或《Linux系统编程》之类的书) 我想让您了解的是，有两种类型的动态分配内存：堆和内存映射段 ( memory mapped segments ) 。从现在开始，我将尝试将这个堆称为 C-堆，以区别于 Erlang 进程堆。我会将一个内存映射段称为“段”，而这张图中的任何栈为 C-栈。

C-堆通过 malloc 分配，段通过mmap分配。

****

关于内存图示

在绘制系统内存和堆栈的概览图示时，我们将遵循内存地址向上增长的惯例。即页面底部的低内存地址和页面顶部的高内存地址。(栈通常从高地址开始向下增长，因此新元素被压栈到最低地址。)

但是，当我们绘制 c-结构体 ( structure ) 时，我们将从上往下绘制字段，尽管结构的第一个字段位于最低地址，而下面的字段位于更高地址。所以包含结构体的图示中，低地址的结构体在页面的顶部，高地址的结构体在页面的底部。

这意味着 c-结构体的图示和内存区域的图示将在页面的地址位置上呈镜像。当我们试图在同一幅图中描绘结构体和堆时，就有点令人困惑。

****

=== 内存子系统

当我们深入到内存子系统中时，我们就可以再次清楚地看到，ERTS 更像是一个操作系统，而不仅仅是一个编程语言环境。ERTS 不仅为 Erlang 进程级别上的 Erlang 项式提供了一个垃圾收集器，而且还提供了大量的低级别内存分配器和内存分配策略。

有关内存分配器的概述，请参阅 erts_alloc 文档：http://www.erlang.org/doc/man/erts_alloc.html

所有这些分配器都带有一些参数，可以用来调整它们的行为，从操作的角度来看，这可能是它最重要的方面之一。在这里，我们可以配置系统行为，以适应从小型嵌入式控制系统 (如 Raspberry Pi)到 Internet 规模的 2TB 的数据库服务器的任何设备。

目前有 11 种不同的分配器，6 种不同的分配策略，以及超过 18 种其他设置，其中一些采用任意的数值输入。这意味着可能的配置有无限多。(好吧，严格地说，它不是无限的，因为每个数字都是有界的，但比你想象的要多。)

为了能够以有意义的方式使用这些设置，我们必须了解这些分配器是如何工作的，以及每个设置如何影响分配器的性能。

erts_alloc 手册给出了以下警告：

[quote, Ericsson AB, http://www.erlang.org/doc/man/erts_alloc.html]

____
WARNING: 只在你绝对清楚自己在做什么的时候使用这些标记。不适当的设置可能导致严重的性能降级甚至操作中的系统崩溃。

____

让你绝对确信你知道自己在做什么，这就是本章要讲的。

当然，我们还将详细介绍垃圾收集器的工作原理。

Oh yes, we will also go into details of how the garbage collector
works.

[[SS-Memory_Allocators]]
=== 不同类型的内存分配器

Erlang 运行时系统正在尽最大努力处理所有情况和所有类型的负载下的内存，但是总会有一些极端情况。在本章中，我们将详细了解内存是如何分配的，以及不同的分配器是如何工作的。有了这个知识和我们稍后将介绍的一些工具，如果您的系统最终出现这些情况，您应该能够检测并修复这些问题。

这里有一个关于系统可能遇到的问题以及如何分析和纠正这种行为的好故事，请阅读 Fred Hébert 的文章 https://blog.heroku.com/archives/2013/11/7/logplex-down-the-rabbit-hole["Troubleshooting Down the Logplex Rabbit Hole"]。

当我们在本书中讨论内存分配器时，它在我们脑海中有一个特定的含义。每个内存分配器管理特定类型的内存的分配和释放。每个分配器用于特定类型的数据，通常专门用于一种大小的数据。

每个内存分配器实现了可以为实际内存分配使用不同算法和设置的分配器接口。

使用不同的分配器的目的是通过分组相同大小的内存分配来减少碎片，并通过降低频繁分配的操作成本来提高性能。

有两种特别的，基本的或通用的内存分配器类型 sys_alloc 和 mseg_alloc，以及通过 alloc_util 框架实现的 9 种特定的分配器。

在下面的小节中，我们将介绍不同的分配器，并稍微介绍一下分配器的通用框架 ( alloc_util )。

每个分配器都有在文档和 C 代码中使用的几个名称。xref:table-allocators[] 列出了所有分配器及其名称。在 C 代码中使用 C-name 来引用分配器。在 erl_alloc.types 中使用了 Type-name，以将分配类型绑定到分配器。Flag 是在启动 Erlang 时用于设置分配器参数的字母。

.内存分配器列表
[[table-allocators]]
[options="header"]
|===============================================================================
|Name                    | Description           | C-name     | Type-name | Flag
| Basic allocator        | malloc interface      | sys_alloc  | SYSTEM    | Y
|Memory segment allocator| mmap interface        | mseg_alloc | -         | M
| Temporary allocator    | Temporary allocations | temp_alloc | TEMPORARY | T
| Heap allocator         | Erlang heap data      | eheap_alloc| EHEAP     | H
| Binary allocator       | Binary data           |binary_alloc| BINARY    | B
| ETS allocator          | ETS data              | ets_alloc  | ETS       | E
| Driver allocator       | Driver data           |driver_alloc| DRIVER    | R
| Short lived allocator  | Short lived memory    | sl_alloc   |SHORT_LIVED| S
| Long lived allocator   | Long lived memory     | ll_alloc   |LONG_LIVED | L
| Fixed allocator        | Fixed size data       | fix_alloc  |FIXED_SIZE | F
| Standard allocator     | For most other data   | std_alloc  | STANDARD  | D
|===============================================================================



==== 基础分配器：sys_alloc

分配器 sys_alloc 不能被禁用，它基本上是直接映射到底层 OS 的 libc 中的 malloc 实现。

如果禁用其他某个特定的分配器，在分配内存时就使用 sys_alloc 作为替代。

所有特定的分配器都根据需要，使用 sys_alloc 或 mseg_alloc 从操作系统分配内存。

当从 OS 分配内存时，sys_alloc 可以在请求的分配数目基础上，添加某个固定数目的额外大小 ( 可能为KB级 ) 作为填充。这样做可以通过过度分配内存来减少系统调用的数量。默认填充大小为 0。

当内存被释放时，sys_alloc 将在释放内存时，在进程中保留一些已经分配的一些空闲内存。这个空闲内存的大小称为对齐阈值，默认为128 KB。这也减少了系统调用的数量，但代价是占用更多的内存。这意味着，如果您使用默认设置运行系统，您可以体验到，当内存被释放时，Beam 进程不会将内存直接返回给操作系统。

sys_alloc 分配的内存区域存储在 beam 进程的 C-堆 中，堆将根据需要通过 brk() 系统调用 (译注：可以参考 link: https://man7.org/linux/man-pages/man2/brk.2.html[brk(2) — Linux manual page] ) 增长 (译注：回顾一下图：xref:program_memory_layout[program_memory_layout] )。

==== 内存段分配器：mseg_alloc

如果底层操作系统支持 mmap，那么某些特定的内存分配器可以使用 mseg_alloc 而不是 sys_alloc 来从操作系统分配内存。

通过 mseg_alloc 分配的内存区域称为段。当一个段被释放时，它不会立即返回到操作系统，而是保存在段缓存中。

当分配一个新的段时，如果可能的话，缓存的段将被重用，就是说重用的一个条件是：如果某个被缓存的段与所请求分配的段的大小相同或缓存段大于请求分配段的大小，但又“不太大”。不太大的含义是 _absolute max cache bad fit_ 的值与差值的比较结果，差值小于这个值将被认为差值“不太大”。这个默认值是 4096 KB。

为了不重用一个 4096 KB 的段来进行一次非常小内存的重用分配，还有一个 _relative_max_cache_bad_fit_ 值，该值表示如果缓存的段大小比请求分配的段大，它们大小的差值如果大于这个百分比，那么它可能不会被使用。它默认值是20%。举例来说，当需要一个10 KB 的段时，最大可以使用一个12 KB 的段。

段缓存中的条目数默认为10，但是可以设置为 0 到 30 之间的任何值。

==== 内存分配器框架：alloc_util

在这两个通用分配器 ( sys_alloc 和 mseg_alloc ) 之上构建的是一个名为 _alloc_util_ 的框架，它用于为不同类型的用法和数据来实现特定的内存分配器。

框架是在 https://github.com/erlang/otp/blob/OTP-23.1/erts/emulator/beam/erl_alloc_util.h[_erl_alloc_util.h_] 和 https://github.com/erlang/otp/blob/OTP-23.1/erts/emulator/beam/erl_alloc_util.c[_erl_alloc_util.c_] 中实现的。ERTS 所使用的各种不同的分配器是在 https://github.com/erlang/otp/blob/OTP-23.1/erts/emulator/beam/erl_alloc.types[erl_alloc.types] 中定义的。

在SMP系统中，通常为每个调度器线程分别提供一套每种类型的分配器。

分配器可以操作的最小内存单位称为块 ( _block_ )。当您调用一个分配器来分配一定数量的内存时，得到的返回是一个块。当你希望释放内存时，块也作为参数提供给分配器。

然而，分配器并不直接从操作系统分配块。相反，分配器通过 sys_alloc 或 mseg_alloc ( 使用 malloc 或者 mmap 实现 ) 从操作系统分配一个载体 ( _carrier_ )。如果使用 sys_alloc，则载体被放在 C-堆上，如果使用 mseg_alloc，则载体被放在一个段中。

小块被放置在多块载体 ( multiblock carrier ) 中。多块载体可以像它的名字一样包含许多块。更大的块放在单块载体 ( singleblock carrier ) 中，就像他的名字意味着只包含一个块一样。

什么是小块，什么是大块是由参数 _singleblock carrier threshold_ (+sbct+) 决定的，请参阅下面的系统标志列表。

大多数分配器也有一个“主多块载体” ( main multiblock carrier )，它永远不会被释放。

[ditaa]
----
 high
 addresses
           |FREE OS MEMORY |
           +---------------+ brk
           |   FREE HEAP   |       | less than MYtt kb
           +---------------+
     /     |  Unused PAD   |  | multiple of Muycs
    |      |---------------|  |
    S      |               |  |    |
singleblock|               |  |    |
 carrier 1 |     Block     |  |    | larger than MSsbct kb
    |      |               |  |    |
     \     |               |  |    |
           +---------------+
     /     |Free in Carrier|       |
    |      |---------------|       |
    S      |               |       |
  main     |               |       |
multiblock |     Block 2   |       | MSmmbcs kb
 carrier   |---------------|       |
    |      |               |       |
     \     |     Block 1   |       |
           +---------------+
           |               |
           |    U S E D    |
           |               |
           +---------------+ start_brk
               C - Heap
 low
 addresses


----

// Want most data un multiblock carriers mbc
// increase sbct, then increase smbcs and lmbcs

===== 内存分配策略

++++
<!--
Are you intending for readers to take advantage of these allocation strategies in their code? If so, this section needs to be much more prominent, and not a subheading in a reference section.  - bmacdonald
-->

++++

内存分配策略被使用，以在多块载体中找到一个空闲的内存块。每种类型的分配器都有一个默认的分配策略，但也可以使用  +as+  标志设置它的分配策略。

Erlang 运行时系统应用程序参考手册列出了以下分配策略:

[quote,'http://www.erlang.org/doc/man/erts_alloc.html[erts_alloc]']
__________________________

_Best fit_：找到满足请求快大小要求的最小块。(bf)

_Address order best fit_：找到满足请求快大小要求的最小块。如果找到多个块，选最低地址的块。(aobf)

_Address order first fit carrier best fit_：找到能满足请求块大小的最低地址的载体，然后使用 "best fit" 策略在该载波中找到一个块。 (aoffcbf)

_Address order first fit carrier address order best fit_：找到能满足请求块大小的最低地址的载体，然后使用 "address order best fit" 策略在该载体内找到一个块。 (aoffcaobf)

_Good fit_：试着找到最适合的，但是只在有限的搜索中找到。(gf)

_A fit_: 不搜索某个合适的，只检查某空闲块看看是否它满足了要求。这个策略只是意在临时分配时被使用。(af)

__________________________



==== 临时分配器：temp_alloc

分配器 _temp_alloc_ 用于临时内存分配。这是非常短暂的分配。temp_alloc 分配的内存，生存期不能超过 Erlang 进程上下文切换。

在函数内执行某些工作时，可以使用 temp_alloc 作为一个临时工作区。把它看作是 C-stack 的扩展，并以同样的方式释放它。也就是说，为了安全起见，从执行分配的函数返回之前，需要释放通过 temp_alloc 分配的内存。在 erl_alloc.types 中有一个注释 (译注，见链接：https://github.com/erlang/otp/blob/OTP-23.1/erts/emulator/beam/erl_alloc.types#L109[erl_alloc.types])，说明在模拟器重新开始执行 Erlang 代码之前应该释放 temp_alloc 块。

注意，与分配器运行在同一调度程序上的 Erlang 进程不可能在释放块之前开始执行 Erlang 代码。这意味着您不能在 BIF 或 NIF 陷阱(yield) 上使用临时分配。

在默认的 R16 SMP 系统中，有N+1 个 temp_alloc 分配器，其中 N 是调度器的数量。temp_alloc 使用 “A fit”(af) 策略。由于 temp_alloc的分配模式基本上是栈分配模式 (大部分大小为0或1)，因此该策略可以很好地工作。

临时分配器在 R16 中用于以下类型的数据：TMP_HEAP、MSG_ROOTS、ROOTSET、LOADER_TEMP、NC_TMP、TMP、DCTRL_BUF、TMP_DIST_BUF、ESTACK、DB_TMP、DB_MC_STK、DB_MS_CMPL_HEAP、LOGGER_DSBUF、TMP_DSBUF、DDLL_TMP_BUF、TEMP_TERM、SYS_READ_BUF、ENVIRONMENT、CON_VPRINT_BUF。

有关每个分配器分配的最新分配类型列表，请参阅erl_alloc.types。( 例如：grep TEMPORARY erts/emulator/beam/erl_allocation .types )。

我不会逐一介绍这些不同的类型，但一般来说，正如通过它们的名称猜测的那样，它们是临时缓冲区或工作堆栈。

The temporary allocator is, in R16, used by the following types of
data: TMP_HEAP, MSG_ROOTS, ROOTSET, LOADER_TEMP, NC_TMP, TMP,
DCTRL_BUF, TMP_DIST_BUF, ESTACK, DB_TMP, DB_MC_STK, DB_MS_CMPL_HEAP,
LOGGER_DSBUF, TMP_DSBUF, DDLL_TMP_BUF, TEMP_TERM, SYS_READ_BUF,
ENVIRONMENT, CON_VPRINT_BUF.

For an up to date list of allocation types allocated with each
allocator, see erl_alloc.types
(e.g. +grep TEMPORARY erts/emulator/beam/erl_alloc.types+).

==== 堆分配器：eheap_alloc

堆分配器用于分配存储 tagged Erlang 项式的内存块，如 Erlang 进程堆(所有代)、堆碎片和 beam_registers。

这可能是您作为 Erlang 开发人员或调优 Erlang 系统时最感兴趣的内存区域。在后面关于垃圾收集和进程内存的部分中，我们将更多地讨论如何管理这些区域。在这里，我们还将介绍什么是堆片段。

==== 二进制数据分配器：binary_alloc

你猜对了，二进制数据 (Binary) 分配器用于分配二进制类型的项式。二进制数据可以有相当不同的大小和不同的生命周期。默认情况下，这个分配器使用  _best fit_  分配策略。

==== ETS 分配器：ets_alloc

ETS 分配器用于大多数 ETS 相关的数据，除了一些短生存期 ( short lived ) 项式或 ETS 表使用的临时数据

==== 驱动 (Driver) 分配器：driver_alloc

驱动分配器用于端口，内联驱动 ( linked in driver ) 和NIF。

==== 短生存期分配器：sl_alloc

短生存期分配器用于预期短生存期的列表和缓冲区。短生存期数据的寿命可能比临时数据长。

// alloc_info_request async bif_timer_sl binary_buffer busy_caller
// busy_caller_table code_ix_lock_q db_fixation db_match_spec_run_heap
// db_proc_cleanup_state ethread_short_lived external_term_data
// extra_port_list extra_root fd_list fixed_del gc_info_request
// misc_aux_work misc_op_list pending_suspend pollset_update_req
// port_names port_task port_task_handle_list prepared_code proc_list
// ptab_list_chunk_info ptab_list_deleted_el ptab_list_pids ptimer_sl
// re_stack re_subject sched_wall_time_request short_lived_thr_queue
// sl_migration_paths ssb system_messages_queue temp_thr_prgr_data
// tmp_cpu_ids unicode_buffer

==== 长生存期分配器：ll_alloc

长生存期分配程序用于长生存期数据，如原子、模块、fun 和长生存期表

// atom_entry atom_tab atom_text aux_work_timeouts bif_timer_table code
// code cpu_data cpu_groups_map cs_prog_path db_match_pseudo_proc
// db_match_pseudo_proc db_tabs ddll_errcodes driver_event_state drv_tab
// ethread_long_lived export_entry export_entry export_tab fd_status
// fd_tab fp_exception fun_entry instr_info internal_async_data
// ll_migration_paths ll_temp_term ll_temp_term long_lived_thr_queue
// misc_aux_work_q module_entry module_tab poll_fds poll_result_events
// pollset port_tab pre_alloc_data preloaded proc_lock_waiter proc_tab
// process_interval run_queue_balancing run_queues scheduler_data
// scheduler_data scheduler_sleep_info select_fds taint_list
// thr_prgr_data thr_prgr_internal_data timer_wheel waiter_object

==== 定长分配器：fix_alloc

定长分配器用于固定大小的对象，如 PCB、消息引用和其他一些对象。固定大小分配器默认使用 _address order best fit_ 分配策略。

// driver_event_data_state driver_select_data_state monitor_sh msg_ref
// nlink_sh proc sl_thr_q_element

==== 标准分配器：std_alloc

其他类型的数据使用标准分配器。( active_procs alloc_info_request arg_reg bif_timer_ll bits_buf bpd calls_buf db_heir_data db_heir_data db_named_table_entry dcache ddll_handle ddll_processes ddll_processes dist_entry dist_tab driver_lock ethread_standard fd_entry_buf fun_tab gc_info_request io_queue line_buf link_lh module_refs monitor_lh monitor_lh monitor_sh
nlink_lh nlink_lh nlink_sh node_entry node_tab nodes_monitor port_data_heap port_lock port_report_exit port_specific_data proc_dict process_specific_data ptimer_ll re_heap reg_proc reg_tab sched_wall_time_request stack suspend_monitor thr_q_element thr_queue zlib )

=== system flags for memory（原书未完成）

原书未完成

=== 进程内存

正如我们在 xref:CH-Processes[] 中看到的那样，进程实际上只是一些内存区域，在本章中，我们将更深入地研究如何管理栈、堆和邮箱。

栈和堆的默认大小是 233 个字。在启动 Erlang 时，可以通过 +pass:[+h]+ 标志对默认大小进行全局更改。在使用 +spawn_opt+ 启动进程时，还可以通过设置 +min_heap_size+ 来设置最小堆大小。

正如我们在 xref:CH-TypeSystem[] 中看到的那样，Erlang 项式都是被标记的，当它们存储在堆上时，它们要么是 cons 单元 ( 列表单元 ) ，要么是装箱对象。

==== 项式共享

堆上的对象在一个进程的上下文中通过引用传递。如果使用元组作为参数调用一个函数，那么只有对该元组的标记引用传递给被调用的函数。在构建新项式时，将只使用对子项式的引用。

例如，如果你有字符串 “hello” (它与这个整数列表相同：[104,101,108,108,111])，你会得到一个类似于:


[[fig-list_layout]]
[ditaa]
----
         ADR                               BINARY  VALUE  +  DESCRIPTION
 hend ->     +-------- -------- -------- --------+
             |              ...                  |
             |              ...                  |
             |00000000 00000000 00000000 10000001| 128 + list tag  ---------------+
 stop ->     |                                   |                                |
                                                                                  |
 htop ->     |                                   |                                |
         132 |00000000 00000000 00000000 01111001| 120 + list tag  -------------- | -+
         128 |00000000 00000000 00000110 10001111| (h) 104 bsl 4 + small int tag <+  |
         124 |00000000 00000000 00000000 01110001| 112 + list tag  ----------------- | -+
         120 |00000000 00000000 00000110 01011111| (e) 101 bsl 4 + small int tag <---+  |
         116 |00000000 00000000 00000000 01110001| 112 + list tag  -------------------- | -+
         112 |00000000 00000000 00000110 11001111| (l) 108 bsl 4 + small int tag <------+  |
         108 |00000000 00000000 00000000 01110001|  96 + list tag  ----------------------- | -+
         104 |00000000 00000000 00000110 11001111| (l) 108 bsl 4 + small int tag <---------+  |
         100 |11111111 11111111 11111111 11111011| NIL                                        |
          96 |00000000 00000000 00000110 11111111| (o) 111 bsl 4 + small int tag <------------+
             |                ...                |
 heap ->     +-----------------------------------+


----

如果您随后创建了一个包含两个列表实例的元组，那么重复的内容就是指向该列表的带标签的指针：00000000000000000000000001000001。代码

----
L = [104, 101, 108, 108, 111],
T = {L, L}.
----

将导致如下所示的内存布局。也就是说，一个装箱头表示这是一个大小为 2 的元组，然后是两个指向同一个列表的指针。

----
ADR VALUE                            DESCRIPTION
144 00000000000000000000000001000001 128+CONS
140 00000000000000000000000001000001 128+CONS
136 00000000000000000000000010000000 2+ARITYVAL
----

这样做很好，因为这样做很节省，而且只占用很少的空间。但如果您将元组发送到另一个进程或执行任何其他类型的IO，或任何导致所谓深拷贝 ( _deep copy_) 的操作，则数据结构将被扩展。因此，如果我们将元组 +T+ 发送到另一个进程 P2 ( +pass:[P2 ! T]+ ) 则 T2 的堆为:

----
 .. TODO
----

通过扩展高度共享的项式，可以很快使 Erlang 节点宕机，请参阅 <<listing-share,share.erl>>。

[source,erlang]
----
-module(share).

-export([share/2, size/0]).

share(0, Y) -> {Y,Y};
share(N, Y) -> [share(N-1, [N|Y]) || _ <- Y].

size() ->
    T = share:share(5,[a,b,c]),
    {{size, erts_debug:size(T)},
     {flat_size, erts_debug:flat_size(T)}}.



 1> timer:tc(fun() -> share:share(10,[a,b,c]), ok end).
 {1131,ok}

 2> share:share(10,[a,b,c]), ok.
 ok

 3> byte_size(list_to_binary(test:share(10,[a,b,c]))), ok.
 HUGE size (13695500364)
 Abort trap: 6

----

可以使用函数 +erts_debug:size/1+ 和 +erts_debug:flat_size/1+ 计算共享项式的内存大小和项式的扩展大小。

[source,erlang]
----
> share:size().
{{size,19386},{flat_size,94110}}

----

对于大多数应用程序来说，这不是问题，但是您应该意识到这个问题，它可能在许多情况下出现。深拷贝用于 IO、ETS 表、binary_to_term 和 消息传递。

让我们更详细地了解消息传递是如何工作的。

==== 消息传递

当进程 P1 向另一个 (本地) 进程 P2 发送消息 M 时，进程 P1 首先计算 M 的扩展大小，然后通过在本地调度器上下文中对 heap_frag 执行 heap_alloc 来分配该大小的新消息缓冲区。

给出 <<listing-send,send.erl>> 中的代码。在 p1/1 send 之前，系统的状态可能是这样的：


[ditaa]
----

    x0       |00000000 00000000 00000000 00100011| Pid 2
    x1       |00000000 00000000 00000000 01001010| 136 + boxed tag -----------+
                                                                              |
                                                                              |
         ADR                               BINARY  VALUE  +  DESCRIPTION      |
 hend ->     +-------- -------- -------- --------+                            |
             |              ...                  |                            |
             |              ...                  |                            |
 stop ->     |                                   |                            |
                                                                              |
 htop ->     |                                   |                            |
         144 |00000000 00000000 00000000 01000001| 128+CONS        ---------------+
         140 |00000000 00000000 00000000 01000001| 128+CONS        ---------------+
         136 |00000000 00000000 00000000 10000000| 2+ARITYVAL             <---+   |
         132 |00000000 00000000 00000000 01111001| 120+CONS        -------------- | -+
         128 |00000000 00000000 00000110 10001111| (h) 104 bsl 4 + small int tag <+  |
         124 |00000000 00000000 00000000 01110001| 112+CONS        ----------------- | -+
         120 |00000000 00000000 00000110 01011111| (e) 101 bsl 4 + small int tag <---+  |
         116 |00000000 00000000 00000000 01110001| 112+CONS        -------------------- | -+
         112 |00000000 00000000 00000110 11001111| (l) 108 bsl 4 + small int tag <------+  |
         108 |00000000 00000000 00000000 01110001|  96+CONS        ----------------------- | -+
         104 |00000000 00000000 00000110 11001111| (l) 108 bsl 4 + small int tag <---------+  |
         100 |11111111 11111111 11111111 11111011| NIL                                        |
          96 |00000000 00000000 00000110 11111111| (o) 111 bsl 4 + small int tag <------------+
             |                ...                |
 heap ->     +-----------------------------------+


P2


----

然后 P1 开始向 P2 发送消息 M。它 (通过 erl_message.c 中的代码) 首先计算 M (在我们的示例中是 23 个字长) footnote:[在这里，我们忽略 tracing，它会在消息大小上增加跟踪标记的空间，并且会使用堆片段] 的平面大小。然后(在SMP系统中)，如果它可以锁定 P2，并且 P2 的堆中有足够的空间，它就会将消息复制到 P2 的堆中。

如果 P2 正在运行 (或退出) 或者堆上没有足够的空间，那么分配一个新的堆片段 (大小为：sizeof ErlHeapFragment - sizeof(Eterm) + 23*sizeof(Eterm)) footnote:[减去一个 sizeof(Eterm) 的原因是，ErlHeapFragment 的内存中已经包含了一个 Eterm 的大小]，初始化后的样子是：

----
erl_heap_fragment:
    ErlHeapFragment* next;	  NULL
    ErlOffHeap off_heap:
      erl_off_heap_header* first; NULL
      Uint64 overhead;               0
    unsigned alloc_size;	    23
    unsigned used_size;             23
    Eterm mem[1];		     ?
      ... 22 free words
----

然后，消息被复制到堆片段中：

----
erl_heap_fragment:
    ErlHeapFragment* next;	  NULL
    ErlOffHeap off_heap:
      erl_off_heap_header* first; Boxed tag+&amp;mem+2*WS-+
      Uint64 overhead;               0                |
    unsigned alloc_size;	    23                |
    unsigned used_size;             23                |
    Eterm mem:                    2+ARITYVAL   <------+
                                  &amp;mem+3*WS+1  ---+
                                  &amp;mem+13*WS+1 ------+
                                  (H*16)+15    <--+  |
                                  &amp;mem+5*WS+1  --+   |
                                  (e*16)+15    <-+   |
                                  &amp;mem+7*WS+1  ----| |
                                  (l*16)+15    <---+ |
                                  &amp;mem+9*WS+1  ---+  |
                                  (l*16)+15    <--+  |
                                  &amp;mem+11*WS+1 ----+ |
                                  (o*16)+15    <---+ |
                                  NIL                |
                                  (H*16)+15    <-----+
                                  &amp;mem+15*WS+1 --+
                                  (e*16)+15    <-+
                                  &amp;mem+17*WS+1 ----|
                                  (l*16)+15    <---+
                                  &amp;mem+19*WS+1 ---+
                                  (l*16)+15    <--+
                                  &amp;mem+21*WS+1 ----+
                                  (o*16)+15    <---+
                                  NIL
----

在这两种情况下，都分配了一个新的mbox (+ErlMessage+)，接收端加一个锁 (+ERTS_PROC_LOCK_MSGQ+)，堆上或新堆片段中的消息链接到 mbox 中。

----
 erl_mesg {
    struct erl_mesg* next = NULL;
    data:  ErlHeapFragment *heap_frag = bp;
    Eterm m[0]            = message;
 } ErlMessage;

----

然后 mbox 被链接到接收方的 in message queue (+msg_inq+) 中，锁被释放。注意 +msg_inq.last+ 指向队列中最后一条消息的 +next+ 字段。当一个新的 mbox 被链接时，下一个指针被更新为指向新的 mbox，最后一个指针被更新为指向新的 mbox 的 next 字段。

[[SS-Binaries]]
==== 二进制数据

As we saw in xref:CH-TypeSystem[] there are four types of binaries
internally. Three of these types, _heap binaries_, _sub binaries_ and
_match contexts_ are stored on the local heap and handled by the
garbage collector and message passing as any other object, copied as
needed.

===== 引用计数

The fourth type.  large binaries or _refc binaries_ on the other hand
are partially stored outside of the process heap and they are
reference counted.

The payload of a refc binary is stored in memory allocated by the
binary allocator. There is also a small reference to the payload call
a ProcBin which is stored on the process heap. This reference is
copied by message passing and by the GC, but the payload is
untouched. This makes it relatively cheap to send large binaries to
other processes since the whole binary doesn't need to be copied.

All references through a ProcBin to a refc binary increases the
reference count of the binary by one. All ProcBin objects on a
process heap are linked together in a linked list. After a
GC pass this linked list is traversed and the reference count
of the binary is decreased with one for each ProcBin that
has deceased. If the reference count of the refc binary
reaches zero that binary is deallocated.

Having large binaries reference counted and not copied by send or
garbage collection is a big win, but there is one problem
with having a mixed environment of garbage collection and
reference counting. In a pure reference counted implementation
the reference count would be reduced as soon as a reference to
the object dies, and when the reference count reaches zero the
object is freed. In the ERTS mixed environment a reference to a
reference counted object does not die until a garbage collection
detects that the reference is dead.

This means that binaries, which has a tendency to be large or even
huge, can hang around for a long time after all references to the
binary are dead. Note that since binaries are allocated globally,
all references from all processes need to be dead, that is all
processes that has seen a binary need to do a GC.

Unfortunately it is not always easy, as a developer, to see which
processes have seen a binary in the GC sense of the word seen. Imagine
for example that you have a load balancer that receives work items
and dispatches them to workers.

In <<load_balancer,this code>> there is an example of a loop which
doesn't need to do GC. (See <<listing-lb,listing lb>> for a full example.)

[[load_balancer]]
----
loop(Workers, N) ->
  receive
    WorkItem ->
       Worker = lists:nth(N+1, Workers),
       Worker ! WorkItem,
       loop(Workers, (N+1) rem length(Workers)) 
  end.
----

This server will just keep on grabbing references to binaries and
never free them, eventually using up all system memory.

When one is aware of the problem it is easy to fix, one can either do
a garbage_collect on each iteration of _loop_ or one could do it every
five seconds or so by adding an after clause to the receive. (_after
5000 -> garbage_collect(), loop(Workers, N)_ ).

===== Sub Binaries and Matching

When you match out a part of a binary you get a sub binary.
This sub binary will be a small structure just containing
pointers into the real binary. This increases the reference
count for the binary but uses very little extra space.

If a match would create a new copy of the matched part of the binary
it would cost both space and time. So in most cases just doing a
pattern match on a binary and getting a sub binary to work on is just
what you want.

There are some degenerate cases, imagine for example that you load
huge file like a book into memory and then you match out a small part
like a chapter to work on. The problem is then that the whole of the
rest of the book is still kept in memory until you are done with
processing the chapter. If you do this for many books, perhaps you
want to get the introduction of every book in your file system, then
you will keep the whole of each book in memory and not just the
introductory chapter. This might lead to huge memory usage.

The solution in this case, when you know you only want one small
part of a large binary and you want to have the small part hanging
around for some time, is to use +binary:copy/1+. This function
is only used for its side effect, which is to actually copy
the sub binary out of the real binary removing the reference to
the larger binary and therefore hopefully letting it be garbage
collected.

There is a pretty thorough explanation of how binary construction
and matching is done in the Erlang documentation:
link:http://www.erlang.org/doc/efficiency_guide/binaryhandling.html[].


==== Garbage Collection

++++
<!--
This part of the content seems to be good, and probably worthy of being a top-level heading. It might be a bit long, though. - bmacdonald
-->
++++


When a process runs out of space on the stack and heap the process
will try to reclaim space by doing a minor garbage collection. The
code for this can be found in
link:https://github.com/erlang/otp/blob/maint/erts/emulator/beam/erl_gc.c[erl_gc.c].


ERTS uses a generational copying garbage collector. A copying
collector means that during garbage collection all live young terms
are copied from the old heap to a new heap. Then the old heap is
discarded. A generational collector works on the principle that
most terms die young, they are temporary terms created, used,
and thrown away. Older terms are promoted to the old generation
which is collected more seldom, with the rational that once
a term has become old it will probably live for a long time.

Conceptually a garbage collection cycle works as follows:

* First you collect all roots (e.g. the stack).
* Then for each root, if the root points to a heap allocated object
which doesn't have a forwarding pointer you copy the object to the new
heap. For each copied object update the original with a forwarding
pointer to the new copy.
* Now go through the new heap and do the same as for the roots.

We will go through an example to see how this is done in
detail. We will go through a minor collection without an
old generation, and we will only use the stack as the root set.
In reality the process dictionary, trace data and probe data
among other things are also included in the rootset.

Let us look at how the call to garbage_collect in the gc_example
behaves. The code will generate a string which is shared by two
elements of a cons and a tuple, the tuple will the be eliminated
resulting in garbage. After the GC there should only be one string on
the heap. That is, first we generate the term 
+{["Hello","Hello"], "Hello"}+ (sharing the same string "Hello" in 
all instances. Then we just keep the term +["Hello","Hello"]+ when
triggering a GC.

NOTE: We will take the opportunity to go through how you, on a
linux system, can use gdb to examine the behavior of ERTS.
You can of course use the debugger of your choice. If you already know
how to use gdb or if you have no interest in going into the debugger
you can just ignore the meta text about how to inspect the system and
just look at the diagrams and the explanations of how the GC works.


[source,erlang]
----
include::../code/memory_chapter/src/gc_example.erl[]
----

After compiling the example I start an erlang shell, test the call
and prepare for a new call to the example (without hitting return):

----
1> gc_example:example().
["Hello","Hello"]
2> spawn(gc_example,example,[]).
----

Then I use gdb to attach to my erlang node (OS PID: 2955 in this case)
----
$ gdb /home/happi/otp/lib/erlang/erts-6.0/bin/beam.smp 2955
----


NOTE: Depending on your settings for ptrace_scope you might have to
precede the gdb invocation with 'sudo'.

Then in gdb I set a breakpoint at the start of the main GC function and
let the node continue:

----
(gdb) break garbage_collect_0
(gdb) cont
Continuing.
----

Now I hit enter in the Erlang shell and execution stops at the breakpoint:

----
Breakpoint 1, garbage_collect_0 (A__p=0x7f673d085f88, BIF__ARGS=0x7f673da90340) at beam/bif.c:3771
3771	    FLAGS(BIF_P) |= F_NEED_FULLSWEEP;
----

Now we can inspect the PCB of the process:

----
(gdb) p *(Process *) A__p
$1 = {common = {id = 1408749273747, refc = {counter = 1}, tracer_proc = 18446744073709551611, trace_flags = 0, u = {alive = {
        started_interval = 0, reg = 0x0, links = 0x0, monitors = 0x0, ptimer = 0x0}, release = {later = 0, func = 0x0, data = 0x0, 
        next = 0x0}}}, htop = 0x7f6737145950, stop = 0x7f6737146000, heap = 0x7f67371458c8, hend = 0x7f6737146010, heap_sz = 233, 
  min_heap_size = 233, min_vheap_size = 46422, fp_exception = 0, hipe = {nsp = 0x0, nstack = 0x0, nstend = 0x0, ncallee = 0x7f673d080000, 
    closure = 0, nstgraylim = 0x0, nstblacklim = 0x0, ngra = 0x0, ncsp = 0x7f673d0863e8, narity = 0, float_result = 0}, arity = 0, 
  arg_reg = 0x7f673d086080, max_arg_reg = 6, def_arg_reg = {393227, 457419, 18446744073709551611, 233, 46422, 2000}, cp = 0x7f673686ac40, 
  i = 0x7f673be17748, catches = 0, fcalls = 1994, rcount = 0, schedule_count = 0, reds = 0, group_leader = 893353197987, flags = 0, 
  fvalue = 18446744073709551611, freason = 0, ftrace = 18446744073709551611, next = 0x7f673d084cc0, nodes_monitors = 0x0, 
  suspend_monitors = 0x0, msg = {first = 0x0, last = 0x7f673d086120, save = 0x7f673d086120, len = 0, mark = 0x0, saved_last = 0x7d0}, u = {
    bif_timers = 0x0, terminate = 0x0}, dictionary = 0x0, seq_trace_clock = 0, seq_trace_lastcnt = 0, 
  seq_trace_token = 18446744073709551611, initial = {393227, 457419, 0}, current = 0x7f673be17730, parent = 1133871366675, 
  approx_started = 1407857804, high_water = 0x7f67371458c8, old_hend = 0x0, old_htop = 0x0, old_heap = 0x0, gen_gcs = 0, 
  max_gen_gcs = 65535, off_heap = {first = 0x0, overhead = 0}, mbuf = 0x0, mbuf_sz = 0, psd = 0x0, bin_vheap_sz = 46422, 
  bin_vheap_mature = 0, bin_old_vheap_sz = 46422, bin_old_vheap = 0, sys_task_qs = 0x0, state = {counter = 41002}, msg_inq = {first = 0x0, 
    last = 0x7f673d086228, len = 0}, pending_exit = {reason = 0, bp = 0x0}, lock = {flags = {counter = 1}, queue = {0x0, 0x0, 0x0, 0x0}, 
    refc = {counter = 1}}, scheduler_data = 0x7f673bd6c080, suspendee = 18446744073709551611, pending_suspenders = 0x0, run_queue = {
    counter = 140081362118912}, hipe_smp = {have_receive_locks = 0}}
----

Wow, that was a lot of information. The interesting part is about the stack and the heap:

----
hend = 0x7f6737146010,
stop = 0x7f6737146000,
htop = 0x7f6737145950,
heap = 0x7f67371458c8,
----

By using some helper scripts we can inspect the stack and the heap in a meaningful
way. (see xref:AP-listings[] for the definitions of the scripts in gdb_script.)

----
(gdb) source gdb_scripts 
(gdb) print_p_stack A__p
0x00007f6737146008 [0x00007f6737145929] cons -> 0x00007f6737145928
(gdb) print_p_heap A__p
0x00007f6737145948 [0x00007f6737145909] cons -> 0x00007f6737145908
0x00007f6737145940 [0x00007f6737145929] cons -> 0x00007f6737145928
0x00007f6737145938 [0x0000000000000080] Tuple size 2
0x00007f6737145930 [0x00007f6737145919] cons -> 0x00007f6737145918
0x00007f6737145928 [0x00007f6737145909] cons -> 0x00007f6737145908
0x00007f6737145920 [0xfffffffffffffffb] NIL
0x00007f6737145918 [0x00007f6737145909] cons -> 0x00007f6737145908
0x00007f6737145910 [0x00007f67371458f9] cons -> 0x00007f67371458f8
0x00007f6737145908 [0x000000000000048f] 72
0x00007f6737145900 [0x00007f67371458e9] cons -> 0x00007f67371458e8
0x00007f67371458f8 [0x000000000000065f] 101
0x00007f67371458f0 [0x00007f67371458d9] cons -> 0x00007f67371458d8
0x00007f67371458e8 [0x00000000000006cf] 108
0x00007f67371458e0 [0x00007f67371458c9] cons -> 0x00007f67371458c8
0x00007f67371458d8 [0x00000000000006cf] 108
0x00007f67371458d0 [0xfffffffffffffffb] NIL
0x00007f67371458c8 [0x00000000000006ff] 111
----

Here we can see the heap of the process after it has allocated the
list "Hello" on the heap and the cons containing that list twice, and
the tuple containing the cons and the list. The _root set_, in this
case the stack, contains a pointer to the cons containing two copies
of the list. The tuple is dead, that is, there are no references to
it.

The garbage collection starts by calculating the root set and by
allocating a new heap (_to space_). By stepping into the GC code in the
debugger you can see how this is done. I will not go through the
details here. After a number of steps the execution will reach the
point where all terms in the root set are copied to the new heap. This
starts around (depending on version) line 1272 with a +while+ loop in
erl_gc.c.

In our case the root is a cons pointing to address 0x00007f95666597f0
containing the letter (integer) 'H'. When a cons cell is moved from
the current heap, called _from space_, to _to space_ the value in the
head (or car) is overwritten with a _moved cons_ tag (the value 0).

After the first step where the root set is moved, the _from space_
and the _to space_ looks like this:

from space:

----
(gdb) print_p_heap p
0x00007f6737145948 [0x00007f6737145909] cons -> 0x00007f6737145908
0x00007f6737145940 [0x00007f6737145929] cons -> 0x00007f6737145928
0x00007f6737145938 [0x0000000000000080] Tuple size 2
0x00007f6737145930 [0x00007f67371445b1] cons -> 0x00007f67371445b0
0x00007f6737145928 [0x0000000000000000] Tuple size 0
0x00007f6737145920 [0xfffffffffffffffb] NIL
0x00007f6737145918 [0x00007f6737145909] cons -> 0x00007f6737145908
0x00007f6737145910 [0x00007f67371458f9] cons -> 0x00007f67371458f8
0x00007f6737145908 [0x000000000000048f] 72
0x00007f6737145900 [0x00007f67371458e9] cons -> 0x00007f67371458e8
0x00007f67371458f8 [0x000000000000065f] 101
0x00007f67371458f0 [0x00007f67371458d9] cons -> 0x00007f67371458d8
0x00007f67371458e8 [0x00000000000006cf] 108
0x00007f67371458e0 [0x00007f67371458c9] cons -> 0x00007f67371458c8
0x00007f67371458d8 [0x00000000000006cf] 108
0x00007f67371458d0 [0xfffffffffffffffb] NIL
0x00007f67371458c8 [0x00000000000006ff] 111
----

to space:

----
(gdb) print_heap n_htop-1 n_htop-2
0x00007f67371445b8 [0x00007f6737145919] cons -> 0x00007f6737145918
0x00007f67371445b0 [0x00007f6737145909] cons -> 0x00007f6737145908

----

In _from space_ the head of the first cons cell has been overwritten
with 0 (looks like a tuple of size 0) and the tail has been overwritten
with a forwarding pointer pointing to the new cons cell in the _to space_.
In _to space_ we now have the first cons cell with two
backward pointers to the head and the tail of the cons in the _from space_.


When the collector is done with the root set the _to space_ contains
backward pointers to all still live terms. At this point the collector
starts sweeping the _to space_. It uses two pointers +n_hp+ pointing to
the bottom of the unseen heap and +n_htop+ pointing to the top of the heap.

----
n_htop:
        0x00007f67371445b8 [0x00007f6737145919] cons -> 0x00007f6737145918
n_hp    0x00007f67371445b0 [0x00007f6737145909] cons -> 0x00007f6737145908
----


The GC will then look at the value pointed to by +n_hp+, in this case a
cons pointing back to the _from space_. So it moves that cons to the to
space, incrementing n_htop to make room for the new cons, and
incrementing +n_hp+ to indicate that the first cons is seen.

----
from space:

0x00007f6737145948 [0x00007f6737145909] cons -> 0x00007f6737145908
0x00007f6737145940 [0x00007f6737145929] cons -> 0x00007f6737145928
0x00007f6737145938 [0x0000000000000080] Tuple size 2
0x00007f6737145930 [0x00007f67371445b1] cons -> 0x00007f67371445b0
0x00007f6737145928 [0x0000000000000000] Tuple size 0
0x00007f6737145920 [0xfffffffffffffffb] NIL
0x00007f6737145918 [0x00007f6737145909] cons -> 0x00007f6737145908
0x00007f6737145910 [0x00007f67371445c1] cons -> 0x00007f67371445c0
0x00007f6737145908 [0x0000000000000000] Tuple size 0
0x00007f6737145900 [0x00007f67371458e9] cons -> 0x00007f67371458e8
0x00007f67371458f8 [0x000000000000065f] 101
0x00007f67371458f0 [0x00007f67371458d9] cons -> 0x00007f67371458d8
0x00007f67371458e8 [0x00000000000006cf] 108
0x00007f67371458e0 [0x00007f67371458c9] cons -> 0x00007f67371458c8
0x00007f67371458d8 [0x00000000000006cf] 108
0x00007f67371458d0 [0xfffffffffffffffb] NIL
0x00007f67371458c8 [0x00000000000006ff] 111

to space:

n_htop:
        0x00007f67371445c8 [0x00007f67371458f9] cons -> 0x00007f67371458f8
        0x00007f67371445c0 [0x000000000000048f] 72
n_hp    0x00007f67371445b8 [0x00007f6737145919] cons -> 0x00007f6737145918
SEEN    0x00007f67371445b0 [0x00007f67371445c1] cons -> 0x00007f67371445c0
----

The same thing then happens with the second cons.

----
from space:

0x00007f6737145948 [0x00007f6737145909] cons -> 0x00007f6737145908
0x00007f6737145940 [0x00007f6737145929] cons -> 0x00007f6737145928
0x00007f6737145938 [0x0000000000000080] Tuple size 2
0x00007f6737145930 [0x00007f67371445b1] cons -> 0x00007f67371445b0
0x00007f6737145928 [0x0000000000000000] Tuple size 0
0x00007f6737145920 [0x00007f67371445d1] cons -> 0x00007f67371445d0
0x00007f6737145918 [0x0000000000000000] Tuple size 0
0x00007f6737145910 [0x00007f67371445c1] cons -> 0x00007f67371445c0
0x00007f6737145908 [0x0000000000000000] Tuple size 0
0x00007f6737145900 [0x00007f67371458e9] cons -> 0x00007f67371458e8
0x00007f67371458f8 [0x000000000000065f] 101
0x00007f67371458f0 [0x00007f67371458d9] cons -> 0x00007f67371458d8
0x00007f67371458e8 [0x00000000000006cf] 108
0x00007f67371458e0 [0x00007f67371458c9] cons -> 0x00007f67371458c8
0x00007f67371458d8 [0x00000000000006cf] 108
0x00007f67371458d0 [0xfffffffffffffffb] NIL
0x00007f67371458c8 [0x00000000000006ff] 111

to space:

n_htop:
        0x00007f67371445d8 [0xfffffffffffffffb] NIL
        0x00007f67371445d0 [0x00007f6737145909] cons -> 0x00007f6737145908
        0x00007f67371445c8 [0x00007f67371458f9] cons -> 0x00007f67371458f8
n_hp    0x00007f67371445c0 [0x000000000000048f] 72
SEEN    0x00007f67371445b8 [0x00007f6737145919] cons -> 0x00007f67371445d0
SEEN    0x00007f67371445b0 [0x00007f67371445c1] cons -> 0x00007f67371445c0
----

The next element in _to space_ is the immediate 72, which is only
stepped over (with `n_hp++`). Then there is another cons which is moved.

The same thing then happens with the second cons.

----
from space:

0x00007f6737145948 [0x00007f6737145909] cons -> 0x00007f6737145908
0x00007f6737145940 [0x00007f6737145929] cons -> 0x00007f6737145928
0x00007f6737145938 [0x0000000000000080] Tuple size 2
0x00007f6737145930 [0x00007f67371445b1] cons -> 0x00007f67371445b0
0x00007f6737145928 [0x0000000000000000] Tuple size 0
0x00007f6737145920 [0x00007f67371445d1] cons -> 0x00007f67371445d0
0x00007f6737145918 [0x0000000000000000] Tuple size 0
0x00007f6737145910 [0x00007f67371445c1] cons -> 0x00007f67371445c0
0x00007f6737145908 [0x0000000000000000] Tuple size 0
0x00007f6737145900 [0x00007f67371445e1] cons -> 0x00007f67371445e0
0x00007f67371458f8 [0x0000000000000000] Tuple size 0
0x00007f67371458f0 [0x00007f67371458d9] cons -> 0x00007f67371458d8
0x00007f67371458e8 [0x00000000000006cf] 108
0x00007f67371458e0 [0x00007f67371458c9] cons -> 0x00007f67371458c8
0x00007f67371458d8 [0x00000000000006cf] 108
0x00007f67371458d0 [0xfffffffffffffffb] NIL
0x00007f67371458c8 [0x00000000000006ff] 111

to space:

n_htop:
        0x00007f67371445e8 [0x00007f67371458e9] cons -> 0x00007f67371458e8
        0x00007f67371445e0 [0x000000000000065f] 101
        0x00007f67371445d8 [0xfffffffffffffffb] NIL
n_hp    0x00007f67371445d0 [0x00007f6737145909] cons -> 0x00007f6737145908
SEEN    0x00007f67371445c8 [0x00007f67371458f9] cons -> 0x00007f67371445e0
SEEN    0x00007f67371445c0 [0x000000000000048f] 72
SEEN    0x00007f67371445b8 [0x00007f6737145919] cons -> 0x00007f67371445d0
SEEN    0x00007f67371445b0 [0x00007f67371445c1] cons -> 0x00007f67371445c0
----

Now we come to a cons that points to a cell that has already been moved.
The GC sees the IS_MOVED_CONS tag at 0x00007f6737145908 and copies the
destination of the moved cell from the tail (`*n_hp++ = ptr[1];`). This
way sharing is preserved during GC. This step does not affect _from space_,
but the backward pointer in to space is rewritten.

----
to space:

n_htop:
        0x00007f67371445e8 [0x00007f67371458e9] cons -> 0x00007f67371458e8
        0x00007f67371445e0 [0x000000000000065f] 101
n_hp    0x00007f67371445d8 [0xfffffffffffffffb] NIL
SEEN    0x00007f67371445d0 [0x00007f67371445c1] cons -> 0x00007f67371445c0
SEEN    0x00007f67371445c8 [0x00007f67371458f9] cons -> 0x00007f67371445e0
SEEN    0x00007f67371445c0 [0x000000000000048f] 72
SEEN    0x00007f67371445b8 [0x00007f6737145919] cons -> 0x00007f67371445d0
SEEN    0x00007f67371445b0 [0x00007f67371445c1] cons -> 0x00007f67371445c0
----

Then the rest of the list (the string) is moved.

----
from space:

0x00007f6737145948 [0x00007f6737145909] cons -> 0x00007f6737145908
0x00007f6737145940 [0x00007f6737145929] cons -> 0x00007f6737145928
0x00007f6737145938 [0x0000000000000080] Tuple size 2
0x00007f6737145930 [0x00007f67371445b1] cons -> 0x00007f67371445b0
0x00007f6737145928 [0x0000000000000000] Tuple size 0
0x00007f6737145920 [0x00007f67371445d1] cons -> 0x00007f67371445d0
0x00007f6737145918 [0x0000000000000000] Tuple size 0
0x00007f6737145910 [0x00007f67371445c1] cons -> 0x00007f67371445c0
0x00007f6737145908 [0x0000000000000000] Tuple size 0
0x00007f6737145900 [0x00007f67371445e1] cons -> 0x00007f67371445e0
0x00007f67371458f8 [0x0000000000000000] Tuple size 0
0x00007f67371458f0 [0x00007f67371445f1] cons -> 0x00007f67371445f0
0x00007f67371458e8 [0x0000000000000000] Tuple size 0
0x00007f67371458e0 [0x00007f6737144601] cons -> 0x00007f6737144600
0x00007f67371458d8 [0x0000000000000000] Tuple size 0
0x00007f67371458d0 [0x00007f6737144611] cons -> 0x00007f6737144610
0x00007f67371458c8 [0x0000000000000000] Tuple size 0

to space:

n_htop:
n_hp
SEEN    0x00007f6737144618 [0xfffffffffffffffb] NIL
SEEN    0x00007f6737144610 [0x00000000000006ff] 111
SEEN    0x00007f6737144608 [0x00007f6737144611] cons -> 0x00007f6737144610
SEEN    0x00007f6737144600 [0x00000000000006cf] 108
SEEN    0x00007f67371445f8 [0x00007f6737144601] cons -> 0x00007f6737144600
SEEN    0x00007f67371445f0 [0x00000000000006cf] 108
SEEN    0x00007f67371445e8 [0x00007f67371445f1] cons -> 0x00007f67371445f0
SEEN    0x00007f67371445e0 [0x000000000000065f] 101
SEEN    0x00007f67371445d8 [0xfffffffffffffffb] NIL
SEEN    0x00007f67371445d0 [0x00007f67371445c1] cons -> 0x00007f67371445c0
SEEN    0x00007f67371445c8 [0x00007f67371445e1] cons -> 0x00007f67371445e0
SEEN    0x00007f67371445c0 [0x000000000000048f] 72
SEEN    0x00007f67371445b8 [0x00007f67371445d1] cons -> 0x00007f67371445d0
SEEN    0x00007f67371445b0 [0x00007f67371445c1] cons -> 0x00007f67371445c0
----

There are some things to note from this example. When terms are
created in Erlang they are created bottom up, starting with the
elements. The garbage collector works top down, starting with the
top level structure and then copying the elements. This means that
the direction of the pointers change after the first GC. This has
no real implications but it is good to know when looking at actual
heaps. You can not assume that structures should be bottom up.

Also note that the GC does a breath first traversal. This means that
locality for one term most often is worse after a GC. With the size of
modern caches this should not be a problem. You could of course create
a pathological example where it becomes a problem, but you can also
create a pathological example where a depth first approach would cause
problems.

The third thing to note is that sharing is preserved which is really
important otherwise we might end up using more space after a GC than
before.

Generations..

[ditaa]
----
  hend ->  +----+
           |....|
  stop ->  |    |
           |    |    +----+ old_hend
           |    |    |    |
  htop ->  |    |    |    |
           |....|    |    | old_htop
           |....|    |....|
  heap ->  +----+    +----+ old_heap
          The Heap   Old Heap


----

 +high_water, old_hend, old_htop, old_heap,
 gen_gcs, max_gen_gcs, off_heap,  mbuf, mbuf_sz, psd, bin_vheap_sz,
 bin_vheap_mature, bin_old_vheap_sz, bin_old_vheap+.

//  ==== TODO
//
// Growth of the stack and heap, Shrinking. No Stack overflow? 
//
// Random thoughts:
//
// Erlang has no updates - there can be no cycles: use reference count.
//
// Erlang terms are small.
//
// The HiPE group did some measures:
// 75% cons cells
// 24% !cons but smaller than 8 words
//  1% >= 8 words
//
// Less fragmentation & better locality with copying collector
//
// Advantages with 1 heap/process:
// + Free reclamation when a process dies
// + Small root set
// + Improved cache locallity
// + Cheap stack/heap test
//
// Disadvantages with 1 heap/process:
// - Message passing is expensive
// - Uses more space (fragmentation)
//

//  The garbage collector, generations, full sweep. 


// Put in pat II:
//  Getting information about stacks,
//  heaps and the GC. 
//  Tweaking stack and heap
//  parameters. 

// Hibernation. 

=== 其他有趣的内存区域（原书未完成）

原书未完成

==== 原子表（原书未完成）

原书未完成

==== 代码 （原书未完成）

原书未完成

==== 常量（原书未完成）

原书未完成


